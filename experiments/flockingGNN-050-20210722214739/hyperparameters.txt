2021/07/22 21:47:39

nAgents = 50
nAgentsMax = 50
repelDist = 1.0
nTrain = 400
nValid = 20
nTest = 20
duration = 2.0
initMinDist = 0.1
accelMax = 10.0
useGPU = False

optimizationAlgorithm = ADAM
learningRate = 0.0005
beta1 = 0.9
beta2 = 0.999
lossFunction = <class 'torch.nn.modules.loss.MSELoss'>
trainer = <class 'alegnn.modules.training.Trainer'>
evaluator = <function evaluateFlocking at 0x7f73047e83a0>
nEpochs = 30
batchSize = 20
doLearningRateDecay = False
learningRateDecayRate = 0.9
learningRateDecayPeriod = 1
validationInterval = 5

name = LocalGNN
archit = <class 'alegnn.modules.architecturesTime.LocalGNN_DB'>
device = cpu
dimNodeSignals = [22, 64]
nFilterTaps = [3]
bias = True
nonlinearity = <class 'torch.nn.modules.activation.Tanh'>
dimReadout = [2]
dimEdgeFeatures = 1

doPrint = True
doLogging = False
doSaveVars = True
doFigs = False
saveDir = experiments/flockingGNN-050-20210722214739
printInterval = 1
figSize = 5
lineWidth = 2
markerShape = o
markerSize = 3
videoSpeed = 0.5
nVideos = 3

nAgentsTest = [50]

name = LocalGNN
thisOptimizationAlgorithm = ADAM
thisTrainer = <class 'alegnn.modules.training.Trainer'>
thisEvaluator = <function evaluateFlocking at 0x7f73047e83a0>
thisLearningRate = 0.0005
thisBeta1 = 0.9
thisBeta2 = 0.999

